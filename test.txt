# Use Amazon Linux 2023 as the base image
FROM public.ecr.aws/amazonlinux/amazonlinux:2023

# Install Node.js and other necessary dependencies
RUN yum update -y && \
    yum install -y \
    gcc-c++ \
    make \
    curl \
    && curl -sL https://rpm.nodesource.com/setup_18.x | bash - && \
    yum install -y nodejs

# Set the working directory
WORKDIR /app

# Copy the package.json and package-lock.json files
COPY package*.json ./

# Install the dependencies
RUN npm install

# Copy the rest of the application files
COPY . .

# Build the React app for production
RUN npm run build

# Install a simple HTTP server to serve the static files
RUN npm install -g serve

# Expose port 3000 to the outside world
EXPOSE 3000

# Command to run the app
CMD ["serve", "-s", "build", "-l", "3000"]


-----------------------------------------------------------------------------------------------


import streamlit as st
import boto3
import json
import os

# Set AWS region
AWS_REGION = "us-east-1"

# Initialize AWS clients
sns_client = boto3.client("sns", region_name=AWS_REGION)
sqs_client = boto3.client("sqs", region_name=AWS_REGION)
lambda_client = boto3.client("lambda", region_name=AWS_REGION)
s3_client = boto3.client("s3", region_name=AWS_REGION)

st.title("AWS Service Tester - SNS, SQS, Lambda, S3")

# ---------------- SNS ----------------
st.header("Amazon SNS - Publish Message")
sns_topic_arn = st.text_input("SNS Topic ARN", "")
sns_message = st.text_area("Message to Publish", "")

if st.button("Publish to SNS"):
    if sns_topic_arn and sns_message:
        response = sns_client.publish(TopicArn=sns_topic_arn, Message=sns_message)
        st.success(f"Message Published! Message ID: {response['MessageId']}")
    else:
        st.warning("Please provide both SNS Topic ARN and a message.")

# ---------------- SQS ----------------
st.header("Amazon SQS - Send & Receive Message")
sqs_queue_url = st.text_input("SQS Queue URL", "")
sqs_message = st.text_area("Message to Send to SQS", "")

if st.button("Send to SQS"):
    if sqs_queue_url and sqs_message:
        response = sqs_client.send_message(QueueUrl=sqs_queue_url, MessageBody=sqs_message)
        st.success(f"Message Sent! Message ID: {response['MessageId']}")
    else:
        st.warning("Please provide both SQS Queue URL and a message.")

if st.button("Receive from SQS"):
    if sqs_queue_url:
        response = sqs_client.receive_message(QueueUrl=sqs_queue_url, MaxNumberOfMessages=1)
        if "Messages" in response:
            message = response["Messages"][0]
            st.write(f"Received Message: {message['Body']}")
            # Delete message after reading
            sqs_client.delete_message(QueueUrl=sqs_queue_url, ReceiptHandle=message["ReceiptHandle"])
            st.success("Message Deleted from SQS")
        else:
            st.warning("No messages in the queue.")
    else:
        st.warning("Please provide the SQS Queue URL.")

# ---------------- Lambda ----------------
st.header("AWS Lambda - Invoke Function")
lambda_function_name = st.text_input("Lambda Function Name", "")
lambda_payload = st.text_area("JSON Payload", "{}")

if st.button("Invoke Lambda"):
    if lambda_function_name:
        try:
            payload_dict = json.loads(lambda_payload)
            response = lambda_client.invoke(
                FunctionName=lambda_function_name,
                InvocationType="RequestResponse",
                Payload=json.dumps(payload_dict),
            )
            response_payload = response["Payload"].read().decode("utf-8")
            st.json(json.loads(response_payload))
        except json.JSONDecodeError:
            st.error("Invalid JSON payload")
    else:
        st.warning("Please provide the Lambda function name.")

# ---------------- S3 ----------------
st.header("Amazon S3 - Upload & List Objects")
s3_bucket_name = st.text_input("S3 Bucket Name", "")

uploaded_file = st.file_uploader("Choose a file to upload", type=["txt", "png", "jpg", "csv", "json"])

if st.button("Upload to S3"):
    if s3_bucket_name and uploaded_file:
        s3_client.upload_fileobj(uploaded_file, s3_bucket_name, uploaded_file.name)
        st.success(f"File '{uploaded_file.name}' uploaded successfully to {s3_bucket_name}.")
    else:
        st.warning("Please provide an S3 bucket name and upload a file.")

if st.button("List S3 Objects"):
    if s3_bucket_name:
        response = s3_client.list_objects_v2(Bucket=s3_bucket_name)
        if "Contents" in response:
            for obj in response["Contents"]:
                st.write(obj["Key"])
        else:
            st.warning("No objects found in the bucket.")
    else:
        st.warning("Please provide an S3 bucket name.")

# ---------------- Combined Workflow ----------------
st.header("Combined AWS Workflow")

combined_topic_arn = st.text_input("SNS Topic ARN for Combined Workflow", "")
combined_sqs_url = st.text_input("SQS Queue URL for Combined Workflow", "")
combined_lambda_name = st.text_input("Lambda Function Name for Combined Workflow", "")
combined_s3_bucket = st.text_input("S3 Bucket Name for Combined Workflow", "")
combined_message = st.text_area("Message for SNS", "")

if st.button("Execute Combined Workflow"):
    if all([combined_topic_arn, combined_sqs_url, combined_lambda_name, combined_s3_bucket, combined_message]):
        # Publish message to SNS
        sns_response = sns_client.publish(TopicArn=combined_topic_arn, Message=combined_message)
        st.success(f"Message Published to SNS: {sns_response['MessageId']}")

        # Receive message from SQS
        sqs_response = sqs_client.receive_message(QueueUrl=combined_sqs_url, MaxNumberOfMessages=1)
        if "Messages" in sqs_response:
            message = sqs_response["Messages"][0]["Body"]
            st.success(f"Message received from SQS: {message}")

            # Invoke Lambda function
            lambda_response = lambda_client.invoke(
                FunctionName=combined_lambda_name,
                InvocationType="RequestResponse",
                Payload=json.dumps({"message": message}),
            )
            lambda_output = lambda_response["Payload"].read().decode("utf-8")
            st.success(f"Lambda Function Output: {lambda_output}")

            # Store result in S3
            s3_client.put_object(Bucket=combined_s3_bucket, Key="lambda_output.json", Body=lambda_output)
            st.success(f"Lambda output stored in S3: lambda_output.json")

            # Delete processed message from SQS
            sqs_client.delete_message(QueueUrl=combined_sqs_url, ReceiptHandle=sqs_response["Messages"][0]["ReceiptHandle"])
            st.success("Message deleted from SQS.")

        else:
            st.warning("No messages in the queue.")
    else:
        st.warning("Please provide all required AWS resources.")

st.write("Built with ‚ù§Ô∏è using Streamlit and AWS SDK (Boto3)")

============================================================================================

import streamlit as st
import boto3
import os

# AWS configuration - make sure your credentials are set via environment variables or ~/.aws/credentials
AWS_ACCESS_KEY = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
AWS_REGION = os.getenv("AWS_REGION", "us-east-1")

# Initialize S3 Client
s3_client = boto3.client(
    "s3",
    aws_access_key_id=AWS_ACCESS_KEY,
    aws_secret_access_key=AWS_SECRET_KEY,
    region_name=AWS_REGION,
)

def list_s3_objects(bucket, prefix=""):
    """
    Lists S3 objects in the given bucket and prefix using Delimiter to simulate folder structure.
    Returns a tuple (directories, files) where directories is a list of dicts from CommonPrefixes,
    and files is a list of dicts from Contents.
    """
    response = s3_client.list_objects_v2(
        Bucket=bucket,
        Prefix=prefix,
        Delimiter='/'
    )
    directories = response.get('CommonPrefixes', [])
    files = response.get('Contents', [])
    return directories, files

st.title("S3 Bucket File Explorer")

# Bucket input
bucket_name = st.text_input("Enter S3 Bucket Name", "")

if bucket_name:
    # Use Streamlit session state to keep track of the current folder (prefix)
    if "current_prefix" not in st.session_state:
        st.session_state.current_prefix = ""

    current_prefix = st.session_state.current_prefix
    st.write(f"**Current folder:** /{current_prefix}")

    # Back navigation if not in the root folder
    if current_prefix:
        if st.button("‚¨ÖÔ∏è Go Back"):
            # Remove the last folder from the current prefix
            prefix_parts = current_prefix.rstrip('/').split('/')
            prefix_parts = prefix_parts[:-1]
            st.session_state.current_prefix = "" if not prefix_parts else "/".join(prefix_parts) + "/"
            st.experimental_rerun()

    # List sub-folders and files in the current folder
    try:
        directories, files = list_s3_objects(bucket_name, current_prefix)

        st.subheader("üìÅ Folders")
        if directories:
            for d in directories:
                folder_full = d.get("Prefix")
                # Display folder name without the current prefix
                display_folder = folder_full.replace(current_prefix, "")
                if st.button(f"üìÇ Open {display_folder}", key=folder_full):
                    st.session_state.current_prefix = folder_full
                    st.experimental_rerun()
        else:
            st.info("No sub-folders found.")

        st.subheader("üìÑ Files")
        # Filter out any key that exactly matches the prefix (if present)
        file_list = [f["Key"] for f in files if f["Key"] != current_prefix]
        if file_list:
            selected_file = st.selectbox("Select a file", file_list, key="file_select")
            if st.button("üóëÔ∏è Delete File"):
                s3_client.delete_object(Bucket=bucket_name, Key=selected_file)
                st.success(f"Deleted {selected_file}")
        else:
            st.info("No files in this folder.")

    except Exception as e:
        st.error(f"Error: {e}")

    # Upload section: Uploads to the current folder (prefix)
    st.subheader("üì§ Upload File")
    uploaded_file = st.file_uploader("Choose a file", type=["png", "jpg", "csv", "txt", "pdf", "json"])
    if uploaded_file and st.button("‚¨ÜÔ∏è Upload File"):
        key = current_prefix + uploaded_file.name  # Upload into current folder
        s3_client.upload_fileobj(uploaded_file, bucket_name, key)
        st.success(f"Uploaded {uploaded_file.name} to /{current_prefix}")

else:
    st.warning("Please enter a bucket name to proceed.")
