# Use Amazon Linux 2023 as the base image
FROM public.ecr.aws/amazonlinux/amazonlinux:2023

# Install Node.js and other necessary dependencies
RUN yum update -y && \
    yum install -y \
    gcc-c++ \
    make \
    curl \
    && curl -sL https://rpm.nodesource.com/setup_18.x | bash - && \
    yum install -y nodejs

# Set the working directory
WORKDIR /app

# Copy the package.json and package-lock.json files
COPY package*.json ./

# Install the dependencies
RUN npm install

# Copy the rest of the application files
COPY . .

# Build the React app for production
RUN npm run build

# Install a simple HTTP server to serve the static files
RUN npm install -g serve

# Expose port 3000 to the outside world
EXPOSE 3000

# Command to run the app
CMD ["serve", "-s", "build", "-l", "3000"]


-----------------------------------------------------------------------------------------------


import streamlit as st
import boto3
import json
import os

# Set AWS region
AWS_REGION = "us-east-1"

# Initialize AWS clients
sns_client = boto3.client("sns", region_name=AWS_REGION)
sqs_client = boto3.client("sqs", region_name=AWS_REGION)
lambda_client = boto3.client("lambda", region_name=AWS_REGION)
s3_client = boto3.client("s3", region_name=AWS_REGION)

st.title("AWS Service Tester - SNS, SQS, Lambda, S3")

# ---------------- SNS ----------------
st.header("Amazon SNS - Publish Message")
sns_topic_arn = st.text_input("SNS Topic ARN", "")
sns_message = st.text_area("Message to Publish", "")

if st.button("Publish to SNS"):
    if sns_topic_arn and sns_message:
        response = sns_client.publish(TopicArn=sns_topic_arn, Message=sns_message)
        st.success(f"Message Published! Message ID: {response['MessageId']}")
    else:
        st.warning("Please provide both SNS Topic ARN and a message.")

# ---------------- SQS ----------------
st.header("Amazon SQS - Send & Receive Message")
sqs_queue_url = st.text_input("SQS Queue URL", "")
sqs_message = st.text_area("Message to Send to SQS", "")

if st.button("Send to SQS"):
    if sqs_queue_url and sqs_message:
        response = sqs_client.send_message(QueueUrl=sqs_queue_url, MessageBody=sqs_message)
        st.success(f"Message Sent! Message ID: {response['MessageId']}")
    else:
        st.warning("Please provide both SQS Queue URL and a message.")

if st.button("Receive from SQS"):
    if sqs_queue_url:
        response = sqs_client.receive_message(QueueUrl=sqs_queue_url, MaxNumberOfMessages=1)
        if "Messages" in response:
            message = response["Messages"][0]
            st.write(f"Received Message: {message['Body']}")
            # Delete message after reading
            sqs_client.delete_message(QueueUrl=sqs_queue_url, ReceiptHandle=message["ReceiptHandle"])
            st.success("Message Deleted from SQS")
        else:
            st.warning("No messages in the queue.")
    else:
        st.warning("Please provide the SQS Queue URL.")

# ---------------- Lambda ----------------
st.header("AWS Lambda - Invoke Function")
lambda_function_name = st.text_input("Lambda Function Name", "")
lambda_payload = st.text_area("JSON Payload", "{}")

if st.button("Invoke Lambda"):
    if lambda_function_name:
        try:
            payload_dict = json.loads(lambda_payload)
            response = lambda_client.invoke(
                FunctionName=lambda_function_name,
                InvocationType="RequestResponse",
                Payload=json.dumps(payload_dict),
            )
            response_payload = response["Payload"].read().decode("utf-8")
            st.json(json.loads(response_payload))
        except json.JSONDecodeError:
            st.error("Invalid JSON payload")
    else:
        st.warning("Please provide the Lambda function name.")

# ---------------- S3 ----------------
st.header("Amazon S3 - Upload & List Objects")
s3_bucket_name = st.text_input("S3 Bucket Name", "")

uploaded_file = st.file_uploader("Choose a file to upload", type=["txt", "png", "jpg", "csv", "json"])

if st.button("Upload to S3"):
    if s3_bucket_name and uploaded_file:
        s3_client.upload_fileobj(uploaded_file, s3_bucket_name, uploaded_file.name)
        st.success(f"File '{uploaded_file.name}' uploaded successfully to {s3_bucket_name}.")
    else:
        st.warning("Please provide an S3 bucket name and upload a file.")

if st.button("List S3 Objects"):
    if s3_bucket_name:
        response = s3_client.list_objects_v2(Bucket=s3_bucket_name)
        if "Contents" in response:
            for obj in response["Contents"]:
                st.write(obj["Key"])
        else:
            st.warning("No objects found in the bucket.")
    else:
        st.warning("Please provide an S3 bucket name.")

# ---------------- Combined Workflow ----------------
st.header("Combined AWS Workflow")

combined_topic_arn = st.text_input("SNS Topic ARN for Combined Workflow", "")
combined_sqs_url = st.text_input("SQS Queue URL for Combined Workflow", "")
combined_lambda_name = st.text_input("Lambda Function Name for Combined Workflow", "")
combined_s3_bucket = st.text_input("S3 Bucket Name for Combined Workflow", "")
combined_message = st.text_area("Message for SNS", "")

if st.button("Execute Combined Workflow"):
    if all([combined_topic_arn, combined_sqs_url, combined_lambda_name, combined_s3_bucket, combined_message]):
        # Publish message to SNS
        sns_response = sns_client.publish(TopicArn=combined_topic_arn, Message=combined_message)
        st.success(f"Message Published to SNS: {sns_response['MessageId']}")

        # Receive message from SQS
        sqs_response = sqs_client.receive_message(QueueUrl=combined_sqs_url, MaxNumberOfMessages=1)
        if "Messages" in sqs_response:
            message = sqs_response["Messages"][0]["Body"]
            st.success(f"Message received from SQS: {message}")

            # Invoke Lambda function
            lambda_response = lambda_client.invoke(
                FunctionName=combined_lambda_name,
                InvocationType="RequestResponse",
                Payload=json.dumps({"message": message}),
            )
            lambda_output = lambda_response["Payload"].read().decode("utf-8")
            st.success(f"Lambda Function Output: {lambda_output}")

            # Store result in S3
            s3_client.put_object(Bucket=combined_s3_bucket, Key="lambda_output.json", Body=lambda_output)
            st.success(f"Lambda output stored in S3: lambda_output.json")

            # Delete processed message from SQS
            sqs_client.delete_message(QueueUrl=combined_sqs_url, ReceiptHandle=sqs_response["Messages"][0]["ReceiptHandle"])
            st.success("Message deleted from SQS.")

        else:
            st.warning("No messages in the queue.")
    else:
        st.warning("Please provide all required AWS resources.")

st.write("Built with ‚ù§Ô∏è using Streamlit and AWS SDK (Boto3)")

============================================================================================

import streamlit as st
import boto3
import os

# AWS configuration - ensure your credentials are set via environment variables or ~/.aws/credentials
AWS_ACCESS_KEY = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
AWS_REGION = os.getenv("AWS_REGION", "us-east-1")

# Initialize S3 Client
s3_client = boto3.client(
    "s3",
    aws_access_key_id=AWS_ACCESS_KEY,
    aws_secret_access_key=AWS_SECRET_KEY,
    region_name=AWS_REGION,
)

def list_s3_objects(bucket, prefix=""):
    """
    List objects in the given bucket and prefix.
    Returns a tuple (directories, files) where:
      - directories: list of sub-folder dictionaries from CommonPrefixes.
      - files: list of file dictionaries from Contents.
    """
    response = s3_client.list_objects_v2(
        Bucket=bucket,
        Prefix=prefix,
        Delimiter='/'
    )
    directories = response.get('CommonPrefixes', [])
    files = response.get('Contents', [])
    return directories, files

st.title("S3 Bucket File Explorer")

# Input for bucket name
bucket_name = st.text_input("Enter S3 Bucket Name", "")

if bucket_name:
    # Initialize the current prefix (folder path) in session state
    if "current_prefix" not in st.session_state:
        st.session_state["current_prefix"] = ""
    
    current_prefix = st.session_state["current_prefix"]
    st.write(f"**Current folder:** /{current_prefix}")

    # Navigation: go back (if not in the root folder)
    if current_prefix:
        if st.button("‚¨ÖÔ∏è Go Back"):
            # Remove the last folder segment from the prefix
            prefix_parts = current_prefix.rstrip('/').split('/')
            prefix_parts = prefix_parts[:-1]
            st.session_state["current_prefix"] = "" if not prefix_parts else "/".join(prefix_parts) + "/"
            # No need to force a re-run; the script re-runs on every widget interaction.

    # List sub-folders and files in the current folder
    try:
        directories, files = list_s3_objects(bucket_name, current_prefix)
        
        st.subheader("üìÅ Folders")
        if directories:
            for d in directories:
                folder_full = d.get("Prefix")
                # Display folder name relative to the current prefix
                display_folder = folder_full.replace(current_prefix, "")
                # When the button is clicked, update the current_prefix to this folder's path.
                if st.button(f"üìÇ Open {display_folder}", key=folder_full):
                    st.session_state["current_prefix"] = folder_full
                    # The script will re-run on the next interaction, showing the updated folder.
        else:
            st.info("No sub-folders found.")
        
        st.subheader("üìÑ Files")
        # Exclude any key that exactly matches the current prefix
        file_list = [f["Key"] for f in files if f["Key"] != current_prefix]
        if file_list:
            selected_file = st.selectbox("Select a file", file_list, key="file_select")
            if st.button("üóëÔ∏è Delete File"):
                s3_client.delete_object(Bucket=bucket_name, Key=selected_file)
                st.success(f"Deleted {selected_file}")
        else:
            st.info("No files in this folder.")

    except Exception as e:
        st.error(f"Error: {e}")

    st.subheader("üì§ Upload File")
    uploaded_file = st.file_uploader("Choose a file", type=["png", "jpg", "csv", "txt", "pdf", "json"])
    if uploaded_file and st.button("‚¨ÜÔ∏è Upload File"):
        # Upload into the current folder
        key = current_prefix + uploaded_file.name
        s3_client.upload_fileobj(uploaded_file, bucket_name, key)
        st.success(f"Uploaded {uploaded_file.name} to /{current_prefix}")

else:
    st.warning("Please enter a bucket name to proceed.")
====================================================================================


import streamlit as st
import boto3
from botocore.credentials import RefreshableCredentials
from botocore.session import get_session
import datetime
import subprocess
import json
import os

# === CONFIGURATION ===
TRUST_ANCHOR_ARN = "arn:aws:rolesanywhere:us-east-1:123456789012:trust-anchor/abcd1234"
PROFILE_ARN = "arn:aws:rolesanywhere:us-east-1:123456789012:profile/efgh5678"
ROLE_ARN = "arn:aws:iam::123456789012:role/MySQSRole"
CERTIFICATE_PATH = "certs/certificate.pem"
PRIVATE_KEY_PATH = "certs/private-key.pem"
SQS_QUEUE_URL = "https://sqs.us-east-1.amazonaws.com/123456789012/my-queue"

# === Function to get temporary credentials using Roles Anywhere ===
def get_temp_creds():
    session = boto3.Session()

    client = session.client("rolesanywhere", region_name="us-east-1")

    response = client.create_session(
        profileArn=PROFILE_ARN,
        roleArn=ROLE_ARN,
        trustAnchorArn=TRUST_ANCHOR_ARN,
        durationSeconds=3600,
        credentialSource={
            "x509CertificateData": open(CERTIFICATE_PATH).read(),
            "privateKeyData": open(PRIVATE_KEY_PATH).read()
        }
    )

    credentials = response["credentialSet"][0]["credentials"]
    return {
        "access_key": credentials["accessKeyId"],
        "secret_key": credentials["secretAccessKey"],
        "session_token": credentials["sessionToken"],
    }

# === Create an SQS client with temporary creds ===
@st.cache_resource
def create_sqs_client():
    creds = get_temp_creds()
    session = boto3.Session(
        aws_access_key_id=creds["access_key"],
        aws_secret_access_key=creds["secret_key"],
        aws_session_token=creds["session_token"],
        region_name="us-east-1"
    )
    return session.client("sqs")

# === Streamlit UI ===
st.title("üì¨ AWS SQS Streamlit App with IAM Roles Anywhere")

client = create_sqs_client()

action = st.radio("Choose action:", ["Send Message", "Receive Message", "Purge Queue"])

if action == "Send Message":
    msg = st.text_area("Enter message to send:")
    if st.button("Send"):
        if msg:
            response = client.send_message(QueueUrl=SQS_QUEUE_URL, MessageBody=msg)
            st.success(f"Message sent! Message ID: {response['MessageId']}")
        else:
            st.warning("Message cannot be empty.")

elif action == "Receive Message":
    if st.button("Receive"):
        response = client.receive_message(
            QueueUrl=SQS_QUEUE_URL,
            MaxNumberOfMessages=1,
            WaitTimeSeconds=2
        )
        messages = response.get("Messages", [])
        if messages:
            msg = messages[0]
            st.write("üì® Message Received:")
            st.json(msg)
            if st.button("Delete Message"):
                client.delete_message(
                    QueueUrl=SQS_QUEUE_URL,
                    ReceiptHandle=msg["ReceiptHandle"]
                )
                st.success("Message deleted!")
        else:
            st.info("No messages available.")

elif action == "Purge Queue":
    if st.button("Purge Queue (Caution!)"):
        client.purge_queue(QueueUrl=SQS_QUEUE_URL)
        st.success("Queue purged!")
